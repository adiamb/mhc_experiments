{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn \n",
    "import scipy\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold, train_test_split, cross_val_score, StratifiedKFold, LabelKFold, ShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from mhcflurry.amino_acid import common_amino_acids\n",
    "from mhcflurry import dataset\n",
    "from mhcflurry.dataset import Dataset\n",
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import math \n",
    "from mhcflurry import peptide_encoding, amino_acid\n",
    "import statsmodels.api as sm\n",
    "from keras import models, layers, optimizers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.utils.layer_utils import layer_from_config\n",
    "from keras.layers import Dense, Dropout, TimeDistributed, Embedding, LSTM, Input, merge, Convolution1D, AveragePooling1D, Activation, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.engine import topology\n",
    "import seaborn as sns\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\"bdata.2009.mhci.public.1.txt\")\n",
    "\n",
    "df['log_meas']=1-np.log(df['meas'])/math.log(50000)\n",
    "df['peptide_length'] = df['sequence'].str.len()\n",
    "\n",
    "\n",
    "max_len=df['sequence'].str.len().max()\n",
    "n_peptides = df['sequence'].count()\n",
    "\n",
    "def amino_acid_hotshot_encoding(s):\n",
    "    return common_amino_acids.hotshot_encoding([s],len(s)).flatten().astype(int)\n",
    "df['hotshot_encoded_peptides'] = df.sequence.apply(lambda seq: amino_acid_hotshot_encoding(seq))\n",
    "\n",
    "def amino_acid_index_encoding(s, maxlen):\n",
    "    a = 1+common_amino_acids.index_encoding([s],len(s)).flatten()\n",
    "    return np.concatenate([a, np.zeros(maxlen-len(a),dtype=int)])\n",
    "df['index_encoded_peptides'] = df.sequence.apply(lambda seq: amino_acid_index_encoding(seq, max_len))\n",
    "\n",
    "def measured_affinity_less_than(Y,k):\n",
    "    IC50 = 50000**(1-Y)\n",
    "    return (IC50 < k).astype(int) \n",
    "\n",
    "def affinity_label(Y):\n",
    "    return measured_affinity_less_than(Y,50) + measured_affinity_less_than(Y,500) + measured_affinity_less_than(Y,5000) + measured_affinity_less_than(Y,50000)\n",
    "\n",
    "df['affinity_label'] = affinity_label(df['log_meas'])\n",
    "df_h = df[df['mhc']=='HLA-A-0201'][['hotshot_encoded_peptides','index_encoded_peptides','log_meas','peptide_length']]\n",
    "X = np.array(list(df_h['index_encoded_peptides']))\n",
    "y = np.array(list(df_h['log_meas']))\n",
    "y[y<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folds = 3\n",
    "batch_size_nn = 16\n",
    "batch_size_lstm = 16\n",
    "hidden = 50\n",
    "dropout_probability = 0.25\n",
    "\n",
    "n_epochs = 50\n",
    "epoch = 0\n",
    "\n",
    "train_lstm_lr_1_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1_3_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1_3_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1_4_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1_4_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "#-----------------------\n",
    "\n",
    "train_lstm_lr_10_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_3_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_3_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_4_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_4_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "#---------------------------\n",
    "\n",
    "train_lstm_lr_100_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_3_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_3_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_4_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_4_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "#-----------------------------------------\n",
    "\n",
    "train_lstm_lr_1000_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1000_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1000_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1000_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1000_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1000_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1000_3_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1000_3_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1000_4_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1000_4_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(KFold(len(df_h),folds, shuffle=True)):\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_1_0 = Adam(lr = 0.05)\n",
    "    lstm_lr_1_0.compile(optimizer = adam_lr_1_0 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_1_1 = Adam(lr = 0.05)\n",
    "    lstm_lr_1_1.compile(optimizer = adam_lr_1_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_1_2 = Adam(lr = 0.05)\n",
    "    lstm_lr_1_2.compile(optimizer = adam_lr_1_2 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1_3 = Model(input = sequence, output = output)\n",
    "    adam_lr_1_3 = Adam(lr = 0.05)\n",
    "    lstm_lr_1_3.compile(optimizer = adam_lr_1_3 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1_4 = Model(input = sequence, output = output)\n",
    "    adam_lr_1_4 = Adam(lr = 0.05)\n",
    "    lstm_lr_1_4.compile(optimizer = adam_lr_1_4 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------------------\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_0 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_0.compile(optimizer = adam_lr_10_0 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_1 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_1.compile(optimizer = adam_lr_10_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_2 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_2.compile(optimizer = adam_lr_10_2 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_3 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_3 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_3.compile(optimizer = adam_lr_10_3 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_4 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_4 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_4.compile(optimizer = adam_lr_10_4 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    #---------------------------------------------------------------------------------\n",
    "\n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_0 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_0.compile(optimizer = adam_lr_100_0 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_1 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_1.compile(optimizer = adam_lr_100_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_2 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_2.compile(optimizer = adam_lr_100_2 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_3 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_3 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_3.compile(optimizer = adam_lr_100_3 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_4 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_4 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_4.compile(optimizer = adam_lr_100_4 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------------------------\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1000_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_1000_0 = Adam(lr = 0.001)\n",
    "    lstm_lr_1000_0.compile(optimizer = adam_lr_1000_0 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1000_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_1000_1 = Adam(lr = 0.001)\n",
    "    lstm_lr_1000_1.compile(optimizer = adam_lr_1000_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1000_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_1000_2 = Adam(lr = 0.001)\n",
    "    lstm_lr_1000_2.compile(optimizer = adam_lr_1000_2 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1000_3 = Model(input = sequence, output = output)\n",
    "    adam_lr_1000_3 = Adam(lr = 0.001)\n",
    "    lstm_lr_1000_3.compile(optimizer = adam_lr_1000_3 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1000_4 = Model(input = sequence, output = output)\n",
    "    adam_lr_1000_4 = Adam(lr = 0.001)\n",
    "    lstm_lr_1000_4.compile(optimizer = adam_lr_1000_4 , loss='mean_squared_error')\n",
    "\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        \n",
    "\n",
    "        adam_lr_1_0.lr.set_value(0.05)\n",
    "        lstm_lr_1_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_1_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1_0_aucs[i][epoch]=train_lstm_lr_1_0_auc\n",
    "        test_lstm_lr_1_0_aucs[i][epoch]=test_lstm_lr_1_0_auc\n",
    "        print(\"LSTM LR = 0.1*t^0 \", train_lstm_lr_1_0_auc, test_lstm_lr_1_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1_0.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        adam_lr_1_1.lr.set_value(0.05*(epoch+1)**(-1))\n",
    "        lstm_lr_1_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_1_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1_1_aucs[i][epoch]=train_lstm_lr_1_1_auc\n",
    "        test_lstm_lr_1_1_aucs[i][epoch]=test_lstm_lr_1_1_auc\n",
    "        print(\"LSTM LR = 0.05*t^(-1) \", train_lstm_lr_1_1_auc, test_lstm_lr_1_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1_1.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_1_2.lr.set_value(0.05*(epoch+1)**(-2))\n",
    "        lstm_lr_1_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_1_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1_2_aucs[i][epoch]=train_lstm_lr_1_2_auc\n",
    "        test_lstm_lr_1_2_aucs[i][epoch]=test_lstm_lr_1_2_auc\n",
    "        print(\"LSTM LR = 0.05*t^(-2) \", train_lstm_lr_1_2_auc, test_lstm_lr_1_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1_2.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        adam_lr_1_3.lr.set_value(0.05*(epoch+1)**(-3))\n",
    "        lstm_lr_1_3.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1_3_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1_3.predict(X[train_idx]))\n",
    "        test_lstm_lr_1_3_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1_3.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1_3_aucs[i][epoch]=train_lstm_lr_1_3_auc\n",
    "        test_lstm_lr_1_3_aucs[i][epoch]=test_lstm_lr_1_3_auc\n",
    "        print(\"LSTM LR = 0.05*t^(-3) \", train_lstm_lr_1_3_auc, test_lstm_lr_1_3_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1_3.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_1_4.lr.set_value(0.05*(epoch+1)**(-4))\n",
    "        lstm_lr_1_4.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1_4_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1_4.predict(X[train_idx]))\n",
    "        test_lstm_lr_1_4_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1_4.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1_4_aucs[i][epoch]=train_lstm_lr_1_4_auc\n",
    "        test_lstm_lr_1_4_aucs[i][epoch]=test_lstm_lr_1_4_auc\n",
    "        print(\"LSTM LR = 0.05*t^(-4) \", train_lstm_lr_1_4_auc, test_lstm_lr_1_4_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1_4.lr.get_value() )\n",
    "        \n",
    "\n",
    "    \n",
    "        #----------------------------------------\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        adam_lr_10_0.lr.set_value(0.01)\n",
    "        lstm_lr_10_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_0_aucs[i][epoch]=train_lstm_lr_10_0_auc\n",
    "        test_lstm_lr_10_0_aucs[i][epoch]=test_lstm_lr_10_0_auc\n",
    "        print(\"LSTM LR = 0.01): \", train_lstm_lr_10_0_auc, test_lstm_lr_10_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_0.lr.get_value() )   \n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_10_1.lr.set_value(0.01*(epoch+1)**(-1))\n",
    "        lstm_lr_10_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_1_aucs[i][epoch]=train_lstm_lr_10_1_auc\n",
    "        test_lstm_lr_10_1_aucs[i][epoch]=test_lstm_lr_10_1_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-1): \", train_lstm_lr_10_1_auc, test_lstm_lr_10_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_1.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_10_2.lr.set_value(0.01*(epoch+1)**(-2))\n",
    "        lstm_lr_10_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_2_aucs[i][epoch]=train_lstm_lr_10_2_auc\n",
    "        test_lstm_lr_10_2_aucs[i][epoch]=test_lstm_lr_10_2_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-2): \", train_lstm_lr_10_2_auc, test_lstm_lr_10_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_2.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_10_3.lr.set_value(0.01*(epoch+1)**(-3))\n",
    "        lstm_lr_10_3.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_3_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_3.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_3_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_3.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_3_aucs[i][epoch]=train_lstm_lr_10_3_auc\n",
    "        test_lstm_lr_10_3_aucs[i][epoch]=test_lstm_lr_10_3_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-3): \", train_lstm_lr_10_3_auc, test_lstm_lr_10_3_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_3.lr.get_value() )\n",
    "        \n",
    "        adam_lr_10_4.lr.set_value(0.01*(epoch+1)**(-4))\n",
    "        lstm_lr_10_4.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_4_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_4.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_4_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_4.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_4_aucs[i][epoch]=train_lstm_lr_10_4_auc\n",
    "        test_lstm_lr_10_4_aucs[i][epoch]=test_lstm_lr_10_4_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-4): \", train_lstm_lr_10_4_auc, test_lstm_lr_10_4_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_4.lr.get_value() )\n",
    "\n",
    "        \n",
    "        #-----------------------------------------------------------------\n",
    "        \n",
    "        \n",
    "        adam_lr_100_0.lr.set_value(0.005)\n",
    "        lstm_lr_100_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_0_aucs[i][epoch]=train_lstm_lr_100_0_auc\n",
    "        test_lstm_lr_100_0_aucs[i][epoch]=test_lstm_lr_100_0_auc\n",
    "        print(\"LSTM LR = 0.005: \", train_lstm_lr_100_0_auc, test_lstm_lr_100_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_0.lr.get_value() )\n",
    "        \n",
    "        adam_lr_100_1.lr.set_value(0.005*(epoch+1)**(-1))\n",
    "        lstm_lr_100_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_1_aucs[i][epoch]=train_lstm_lr_100_1_auc\n",
    "        test_lstm_lr_100_1_aucs[i][epoch]=test_lstm_lr_100_1_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-1}: \", train_lstm_lr_100_1_auc, test_lstm_lr_100_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_1.lr.get_value() )\n",
    "        \n",
    "        adam_lr_100_2.lr.set_value(0.005*(epoch+1)**(-2))\n",
    "        lstm_lr_100_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_2_aucs[i][epoch]=train_lstm_lr_100_2_auc\n",
    "        test_lstm_lr_100_2_aucs[i][epoch]=test_lstm_lr_100_2_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-2}: \", train_lstm_lr_100_2_auc, test_lstm_lr_100_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_2.lr.get_value() )\n",
    "        \n",
    "        adam_lr_100_3.lr.set_value(0.005*(epoch+1)**(-3))\n",
    "        lstm_lr_100_3.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_3_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_3.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_3_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_3.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_3_aucs[i][epoch]=train_lstm_lr_100_3_auc\n",
    "        test_lstm_lr_100_3_aucs[i][epoch]=test_lstm_lr_100_3_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-3}: \", train_lstm_lr_100_3_auc, test_lstm_lr_100_3_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_3.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        adam_lr_100_4.lr.set_value(0.005*(epoch+1)**(-4))\n",
    "        lstm_lr_100_4.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_4_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_4.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_4_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_4.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_4_aucs[i][epoch]=train_lstm_lr_100_4_auc\n",
    "        test_lstm_lr_100_4_aucs[i][epoch]=test_lstm_lr_100_4_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-4}: \", train_lstm_lr_100_4_auc, test_lstm_lr_100_4_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_4.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        #-------------------------------------------------------------------\n",
    "        \n",
    "        adam_lr_1000_0.lr.set_value(0.001)\n",
    "        lstm_lr_1000_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1000_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1000_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_1000_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1000_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1000_0_aucs[i][epoch]=train_lstm_lr_1000_0_auc\n",
    "        test_lstm_lr_1000_0_aucs[i][epoch]=test_lstm_lr_1000_0_auc\n",
    "        print(\"LSTM LR = 0.001: \", train_lstm_lr_1000_0_auc, test_lstm_lr_1000_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1000_0.lr.get_value() )\n",
    "        \n",
    "        adam_lr_1000_1.lr.set_value(0.001*(epoch+1)**(-1))\n",
    "        lstm_lr_1000_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1000_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1000_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_1000_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1000_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1000_1_aucs[i][epoch]=train_lstm_lr_1000_1_auc\n",
    "        test_lstm_lr_1000_1_aucs[i][epoch]=test_lstm_lr_1000_1_auc\n",
    "        print(\"LSTM LR = 0.001*t^{-1}: \", train_lstm_lr_1000_1_auc, test_lstm_lr_1000_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1000_1.lr.get_value() )\n",
    "\n",
    "        adam_lr_1000_2.lr.set_value(0.001*(epoch+1)**(-2))\n",
    "        lstm_lr_1000_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1000_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1000_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_1000_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1000_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1000_2_aucs[i][epoch]=train_lstm_lr_1000_2_auc\n",
    "        test_lstm_lr_1000_2_aucs[i][epoch]=test_lstm_lr_1000_2_auc\n",
    "        print(\"LSTM LR = 0.001*t^{-2}: \", train_lstm_lr_1000_2_auc, test_lstm_lr_1000_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1000_2.lr.get_value() )\n",
    "        \n",
    "        adam_lr_1000_3.lr.set_value(0.001*(epoch+1)**(-3))\n",
    "        lstm_lr_1000_3.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1000_3_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1000_3.predict(X[train_idx]))\n",
    "        test_lstm_lr_1000_3_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1000_3.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1000_3_aucs[i][epoch]=train_lstm_lr_1000_3_auc\n",
    "        test_lstm_lr_1000_3_aucs[i][epoch]=test_lstm_lr_1000_3_auc\n",
    "        print(\"LSTM LR = 0.001*t^{-3}: \", train_lstm_lr_1000_3_auc, test_lstm_lr_1000_3_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1000_3.lr.get_value() )\n",
    "        \n",
    "        adam_lr_1000_4.lr.set_value(0.001*(epoch+1)**(-4))\n",
    "        lstm_lr_1000_4.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1000_4_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1000_4.predict(X[train_idx]))\n",
    "        test_lstm_lr_1000_4_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1000_4.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1000_4_aucs[i][epoch]=train_lstm_lr_1000_4_auc\n",
    "        test_lstm_lr_1000_4_aucs[i][epoch]=test_lstm_lr_1000_4_auc\n",
    "        print(\"LSTM LR = 0.001*t^{-4}: \", train_lstm_lr_1000_4_auc, test_lstm_lr_1000_4_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1000_4.lr.get_value() )\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lstm_lr_100_aucs_mean = np.mean(train_lstm_lr_100_aucs, axis=0)\n",
    "test_lstm_lr_100_aucs_mean = np.mean(test_lstm_lr_100_aucs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S_1 = pd.Series( [test_lstm_lr_1_0_aucs[0][26],\n",
    "test_lstm_lr_1_1_aucs[0][26],\n",
    "test_lstm_lr_1_2_aucs[0][26],\n",
    "test_lstm_lr_1_3_aucs[0][26],\n",
    "test_lstm_lr_1_4_aucs[0][26]], index = ['t^0','1/t','1/t^2','1/t^3','1/t^4'])\n",
    "\n",
    "S_10 = pd.Series([test_lstm_lr_10_0_aucs[0][26],\n",
    "test_lstm_lr_10_1_aucs[0][26],\n",
    "test_lstm_lr_10_2_aucs[0][26],\n",
    "test_lstm_lr_10_3_aucs[0][26],\n",
    "test_lstm_lr_10_4_aucs[0][26]], index = ['t^0','1/t','1/t^2','1/t^3','1/t^4'])\n",
    "\n",
    "S_100 = pd.Series([test_lstm_lr_100_0_aucs[0][26],\n",
    "test_lstm_lr_100_1_aucs[0][26],\n",
    "test_lstm_lr_100_2_aucs[0][26],\n",
    "test_lstm_lr_100_3_aucs[0][26],\n",
    "test_lstm_lr_100_4_aucs[0][26]], index = ['t^0','1/t','1/t^2','1/t^3','1/t^4'])\n",
    "\n",
    "S_1000 = pd.Series([test_lstm_lr_1000_0_aucs[0][26],\n",
    "test_lstm_lr_1000_1_aucs[0][26],\n",
    "test_lstm_lr_1000_2_aucs[0][26],\n",
    "test_lstm_lr_1000_3_aucs[0][26],\n",
    "test_lstm_lr_1000_4_aucs[0][26]], index = ['t^0','1/t','1/t^2','1/t^3','1/t^4'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cf492550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAFRCAYAAAAfClZfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf4b0e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = {'LR = 0.05': S_1,\n",
    "     'LR = 0.01': S_10,\n",
    "     'LR = 0.005': S_100,\n",
    "     'LR = 0.001': S_1000}\n",
    "data_frame = pd.DataFrame(d) \n",
    "blu = sns.light_palette(\"navy\", as_cmap= True)\n",
    "sns.heatmap(data_frame, cmap= blu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lstm_lr_100_aucs_mean = np.mean(train_lstm_lr_100_aucs, axis=0)\n",
    "test_lstm_lr_100_aucs_mean = np.mean(test_lstm_lr_100_aucs, axis=0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
